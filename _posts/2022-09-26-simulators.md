---
layout: post
title: Summary Post on Simulators by Janus
---
This post summarizes https://generative.ink/posts/simulators/

Janus is the pseudonym of some new provocateur on the AI alignment forums. Last week he released a confident manifesto on a new framing for GPT-class models that has been as well received by the community as anything I have witnessed. 

His contribution to the zeitgeist of understanding of GPT-class models, is to frame them as a type of "simulator". This separates their ilk from the ways we've looked at models up til now, variously as agents, oracles, or tools. 

Here's why this is important. 

Much alignment research has been centered around seeing Reinforcement Learning models as the likely format that general AI will take. The way agents are trained, is to maximize some utility function. Alignment researcheres were afraid that a capable enough model might override sane boundaries in the quest to achieve it's goal. 

However, GPT is not a RL agent. GPT is not run constantly, keeping track of state. All state in GPT is from the text output on the page that it is creating. It isn't trying to do anything, other than to create a "real-sounding" continuation of some bit of text. This may sound much more 
